x-common-depends: &common_depends
  depends_on:
    - minio
    - jaeger
    - tempo
    - loki
    - promtail

services:

  livebook:
    image: ghcr.io/livebook-dev/livebook:nightly
    container_name: msvc-livebook
    hostname: livebook.msvc_default
    ports:
      - 8090:8090
      - 8091:8091
    environment:
      - LIVEBOOK_PORT=8090
      - LIVEBOOK_IFRAME_PORT=8091
      - LIVEBOOK_DISTRIBUTION=name
      - LIVEBOOK_COOKIE=${ERL_COOKIE}
      - LIVEBOOK_PASSWORD=${LIVEBOOK_PASSWORD}
      - LIVEBOOK_SECRET_KEY_BASE=IItyxAvQuUY4qKyolIxEJc5aMT+B7xp3sAZyhxbruzYa7Yar4PL0WWj3dMxySrwj
      - LIVEBOOK_NODE=livebook@livebook.msvc_default
    volumes:
      - ./apps/notebooks:/data/
      - ./apps:/workspace/apps:ro # Mount apps for inspection
    networks:
      - msvc_default
    env_file:
      - .env.staging
  user_svc:
    build:
      context: . # Build from monorepo root to access libs/
      dockerfile: apps/user_svc/Dockerfile
      args:
        OS: ${OS}
        ELIXIR_IMAGE: ${ELIXIR_IMAGE}

    container_name: msvc-user-svc
    hostname: user_svc.msvc_default
    ports:
      - ${USER_SVC_PORT}:${USER_SVC_HOST_PORT}

    develop:
      watch:
        - action: rebuild
          path: ./apps/user_svc/lib
        - action: rebuild
          path: ./apps/user_svc/mix.exs
        - action: rebuild
          path: ./libs/protos # Rebuild when protos change
        - action: rebuild
          path: ./apps/user_svc/config/config.exs

    env_file:
      - .env.staging

    environment:
      SERVICE: "user_svc"
      RELEASE_COOKIE: ${ERL_COOKIE}
      RELEASE_DISTRIBUTION: "name"
      RELEASE_NODE: "user_svc@user_svc.msvc_default"
      # Service-specific overrides
      PORT: "${USER_SVC_PORT}"
      OTEL_SERVICE_NAME: "user_svc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4317" # Send to Jaeger for better UI

      # Docker-specific config (override .env for internal networking)
      MINIO_HOST: "minio"
      USER_SVC_URL: "http://user_svc:${USER_SVC_PORT}"
      JOB_SVC_URL: "http://job_svc:${JOB_SVC_PORT}"
      CLIENT_SVC_URL: "http://client_svc:${CLIENT_SVC_PORT}"

    <<: *common_depends

    networks:
      - msvc_default

    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://127.0.0.1:${USER_SVC_PORT}/health" ]
      interval: 30s
      timeout: 3s
      retries: 3

  # Client Service
  client_svc:
    build:
      context: . # Build from monorepo root to access libs/
      dockerfile: apps/client_svc/Dockerfile
      args:
        OS: ${OS}
        ELIXIR_IMAGE: ${ELIXIR_IMAGE}

    container_name: msvc-client-svc
    hostname: client_svc.msvc_default
    ports:
      - ${CLIENT_SVC_PORT}:${CLIENT_SVC_HOST_PORT}

    develop:
      watch:
        - action: rebuild
          path: ./apps/client_svc/lib
        - action: rebuild
          path: ./apps/client_svc/mix.exs
        - action: rebuild
          path: ./libs/protos # Rebuild when protos change

    env_file:
      - .env.staging

    environment:
      SERVICE: "client_svc"
      RELEASE_COOKIE: ${ERL_COOKIE}
      RELEASE_DISTRIBUTION: "name"
      RELEASE_NODE: "client_svc@client_svc.msvc_default"
      # Service-specific overrides
      PORT: ${CLIENT_SVC_PORT}
      OTEL_SERVICE_NAME: "client_svc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4317"
      USER_SVC_URL: "http://user_svc:${USER_SVC_PORT}"

    <<: *common_depends

    networks:
      - msvc_default

    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://127.0.0.1:${CLIENT_SVC_PORT}/health" ]
      interval: 30s
      timeout: 3s
      retries: 3

  # Job Service
  job_svc:
    build:
      context: . # Build from monorepo root to access libs/
      dockerfile: apps/job_svc/Dockerfile
      args:
        OS: ${OS}
        ELIXIR_IMAGE: ${ELIXIR_IMAGE}

    container_name: msvc-job-svc
    hostname: job_svc.msvc_default
    ports:
      - ${JOB_SVC_PORT}:${JOB_SVC_HOST_PORT}

    develop:
      watch:
        - action: rebuild
          path: ./apps/job_svc/lib
        - action: rebuild
          path: ./apps/job_svc/mix.exs
        - action: rebuild
          path: ./libs/protos # Rebuild when protos change

    env_file:
      - .env.staging

    environment:
      RELEASE_COOKIE: ${ERL_COOKIE}
      RELEASE_DISTRIBUTION: "name"
      RELEASE_NODE: "job_svc@job_svc.msvc_default"
      PORT: ${JOB_SVC_PORT}
      OTEL_SERVICE_NAME: "job_svc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4317" # Send to Jaeger for better UI
      DATABASE_PATH: "/app/db/job_service.db"

      # Docker-specific config (override .env for internal networking)
      MINIO_HOST: "minio"
      MINIO_SCHEME: "http://"
      IMAGE_SVC_URL: "http://image_svc:${IMAGE_SVC_PORT}"
      EMAIL_SVC_URL: "http://email_svc:${EMAIL_SVC_PORT}"
      USER_SVC_URL: "http://user_svc:${USER_SVC_PORT}"
      IMAGE_SVC: "msvc-images"

    volumes:
      - job-data:/app/db # Persist SQLite database

    <<: *common_depends

    networks:
      - msvc_default

    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://127.0.0.1:${JOB_SVC_PORT}/health" ]
      interval: 30s
      timeout: 3s
      retries: 3

  # Image Service
  image_svc:
    build:
      context: . # Build from monorepo root to access libs/
      dockerfile: apps/image_svc/Dockerfile
      args:
        OS: ${OS}
        ELIXIR_IMAGE: ${ELIXIR_IMAGE}

    container_name: msvc-image-svc
    hostname: image_svc.msvc_default
    ports:
      - ${IMAGE_SVC_PORT}:${IMAGE_SVC_HOST_PORT}

    develop:
      watch:
        - action: rebuild
          path: ./apps/image_svc/lib
        - action: rebuild
          path: ./apps/image_svc/mix.exs
        - action: rebuild
          path: ./libs/protos # Rebuild when protos change

    env_file:
      - .env.staging

    environment:
      RELEASE_COOKIE: ${ERL_COOKIE}
      RELEASE_DISTRIBUTION: "name"
      DATABASE_PATH: /app/db/conversion_cache.sql3
      # Service-specific overrides
      PORT: ${IMAGE_SVC_PORT}
      OTEL_SERVICE_NAME: "image_svc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4317" # Send to Jaeger for better UI

      # Docker-specific config (override .env for internal networking)
      MINIO_HOST: "minio"
      MINIO_SCHEME: "http://"
      USER_SVC_URL: "http://user_svc:${USER_SVC_PORT}"

    <<: *common_depends

    networks:
      - msvc_default

    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://127.0.0.1:${IMAGE_SVC_PORT}/health" ]

      interval: 30s
      timeout: 3s
      retries: 3

  # Email Service
  email_svc:
    build:
      context: . # Build from monorepo root to access libs/
      dockerfile: apps/email_svc/Dockerfile
      args:
        OS: ${OS}
        ELIXIR_IMAGE: ${ELIXIR_IMAGE}

    container_name: msvc-email-svc
    hostname: email_svc.msvc_default
    ports:
      - ${EMAIL_SVC_PORT}:${EMAIL_SVC_HOST_PORT}

    develop:
      watch:
        - action: rebuild
          path: ./apps/email_svc/lib
        - action: rebuild
          path: ./apps/email_svc/mix.exs
        - action: rebuild
          path: ./libs/protos # Rebuild when protos change

    env_file:
      - .env.staging

    environment:
      RELEASE_COOKIE: ${ERL_COOKIE}
      RELEASE_DISTRIBUTION: "name"
      PORT: ${EMAIL_SVC_PORT}
      OTEL_SERVICE_NAME: "email_svc"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://jaeger:4317" # Send to Jaeger for better UI
      MAILER_ADAPTER: "local"

    <<: *common_depends

    networks:
      - msvc_default

    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://127.0.0.1:${EMAIL_SVC_PORT}/health" ]
      interval: 30s
      timeout: 3s
      retries: 3

  minio:
    image: minio/minio:latest
    container_name: msvc-minio
    ports:
      - ${MINIO_PORT}:9000 # API port
      - ${MINIO_CONSOLE_PORT}:9001 # Console UI port
    env_file:
      - .env.staging
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://127.0.0.1:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3

  # MinIO initialization - creates required buckets
  minio-init:
    image: minio/mc:latest
    container_name: msvc-minio-init
    env_file:
      - .env.staging
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - msvc_default
    entrypoint: >
      /bin/sh -c " mc alias set local http://minio:9000 $${MINIO_ROOT_USER} $${MINIO_ROOT_PASSWORD}; mc mb --ignore-existing local/msvc-images; mc mb --ignore-existing local/loki-chunks; mc mb --ignore-existing local/tempo-traces; echo 'MinIO buckets initialized successfully (msvc-images, loki-chunks, tempo-traces)'; "

  tempo:
    image: grafana/tempo:latest
    container_name: msvc-tempo
    ports:
      - ${TEMPO_UI_PORT:-3200}:3200 # Tempo Query UI (optional)
      - ${TEMPO_OTLP_GRPC_PORT:-4317}:4317 # OTLP gRPC receiver (RECOMMENDED for production)
      - ${TEMPO_OTLP_HTTP_PORT:-4318}:4318 # OTLP HTTP receiver (fallback)
    command: -config.file=/etc/tempo/tempo.yml
    volumes:
      - ./o11y_configs/tempo/tempo.yml:/etc/tempo/tempo.yml
    tmpfs:
      - /tmp/tempo:mode=1777,size=1G # Temporary storage for WAL and cache (writable by all users)
    environment:
      - LOG_LEVEL=info
    depends_on:
      - minio-init # Wait for MinIO buckets
    networks:
      - msvc_default
    # Note: Tempo image doesn't include wget/curl, so we skip healthcheck
    # Tempo logs show "Tempo started" when ready

    # Jaeger - Distributed tracing UI (better UX than Tempo, shares OTLP traces)
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: msvc-jaeger
    ports:
      - ${JAEGER_UI_PORT:-16686}:16686 # Jaeger UI
      - ${JAEGER_OTLP_GRPC_PORT:-4327}:4317 # OTLP gRPC receiver (different host port to avoid conflict with Tempo)
      - ${JAEGER_OTLP_HTTP_PORT:-4328}:4318 # OTLP HTTP receiver
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=memory # In-memory storage (for dev)
      - LOG_LEVEL=info
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://127.0.0.1:16686/" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:latest
    container_name: msvc-prometheus
    ports:
      - ${PROMETHEUS_UI_PORT}:9090 # Prometheus UI and API
    volumes:
      - ./o11y_configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    depends_on:
      - user_svc
      - client_svc
      - job_svc
      - image_svc
      - email_svc
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://127.0.0.1:9090/-/healthy" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Loki - Log aggregation (like Prometheus but for logs)
  loki:
    image: grafana/loki:latest
    container_name: msvc-loki
    ports:
      - ${LOKI_PORT}:3100 # Loki API
    command: -config.file=/etc/loki/config.yml
    volumes:
      - ./o11y_configs/loki/config.yml:/etc/loki/config.yml # Mount custom config with MinIO
      - loki-data:/loki
    depends_on:
      - minio-init # Wait for MinIO buckets to be initialized
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://127.0.0.1:3100/ready" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Promtail - Log shipper (reads Docker logs and sends to Loki)
  promtail:
    image: grafana/promtail:latest
    container_name: msvc-promtail
    ports:
      - "9080:9080" # Promtail HTTP
    volumes:
      - ./o11y_configs/promtail/config.yml:/etc/promtail/config.yml
      - /var/run/docker.sock:/var/run/docker.sock:ro # Read Docker container logs
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      loki:
        condition: service_healthy
    networks:
      - msvc_default
    restart: unless-stopped

  # Grafana - Visualization for logs AND metrics
  grafana:
    image: grafana/grafana:latest
    container_name: msvc-grafana
    ports:
      - ${GRAFANA_UI_PORT}:3000 # Grafana UI
    env_file:
      - .env.staging
    volumes:
      - grafana-data:/var/lib/grafana
      - ./o11y_configs/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./o11y_configs/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - loki
      - tempo
      - prometheus
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://127.0.0.1:3000/api/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # Swagger UI - Interactive API Documentation (for testing)
  swagger-ui:
    image: swaggerapi/swagger-ui:latest
    container_name: msvc-swagger-ui
    ports:
      - ${SWAGGER_UI_PORT}:8080
    env_file:
      - .env.staging
    environment:
      # Service-specific configuration
      URLS: >
        [
          { url: "specs/client_svc.yaml", name: "Client Service (${CLIENT_SVC_PORT})"},
          { url: "specs/user_svc.yaml", name: "User Service (${USER_SVC_PORT})" },
          { url: "specs/job_svc.yaml", name: "Job Service (${JOB_SVC_PORT})" },
          { url: "specs/image_svc.yaml", name: "Image Service (${IMAGE_SVC_PORT})" },
          { url: "specs/email_svc.yaml", name: "Email Service (${EMAIL_SVC_PORT})" }
        ]
      URLS_PRIMARY_NAME: "Client Service (${CLIENT_SVC_PORT})"
    volumes:
      - ./openapi:/usr/share/nginx/html/specs:ro
    networks:
      - msvc_default
    healthcheck:
      test: [ "CMD", "wget", "--spider", "-q", "http://127.0.0.1:8080" ]
      interval: 30s
      timeout: 10s
      retries: 3
  # OpenSearch removed - Tempo uses MinIO for storage instead

volumes:
  minio-data:
    driver: local
  loki-data:
    driver: local
  grafana-data:
    driver: local
  job-data:
    driver: local
  prometheus-data:
    driver: local

networks:
  msvc_default:
